{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72c883fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import demoji\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5564a5ca",
   "metadata": {},
   "source": [
    "# Load DataSet and Data Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51e2b8c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>type_company</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>city</th>\n",
       "      <th>avg_stars_num</th>\n",
       "      <th>n_reviews_num</th>\n",
       "      <th>encoded_user</th>\n",
       "      <th>local_guide</th>\n",
       "      <th>clean_other_review_num</th>\n",
       "      <th>published_date</th>\n",
       "      <th>today_date</th>\n",
       "      <th>stars_num</th>\n",
       "      <th>review_EN</th>\n",
       "      <th>original_lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Caretrex warehousing &amp; logistics</td>\n",
       "      <td>Logistics service</td>\n",
       "      <td>51.593721</td>\n",
       "      <td>5.073492</td>\n",
       "      <td>Tilburg</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>HHpDM</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2 years ago</td>\n",
       "      <td>2022-09-24</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Caretrex warehousing &amp; logistics</td>\n",
       "      <td>Logistics service</td>\n",
       "      <td>51.593721</td>\n",
       "      <td>5.073492</td>\n",
       "      <td>Tilburg</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>dYFWx</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5 years ago</td>\n",
       "      <td>2022-09-24</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FEFA Logistics</td>\n",
       "      <td>Trucking company</td>\n",
       "      <td>51.480074</td>\n",
       "      <td>5.446764</td>\n",
       "      <td>Eindhoven</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dekkers Transport Holland</td>\n",
       "      <td>Trucking company</td>\n",
       "      <td>51.597249</td>\n",
       "      <td>5.027990</td>\n",
       "      <td>Tilburg</td>\n",
       "      <td>4.6</td>\n",
       "      <td>53.0</td>\n",
       "      <td>Pp1)c</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>a year ago</td>\n",
       "      <td>2022-09-24</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Best employer ever. Worked there for approxima...</td>\n",
       "      <td>ENG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dekkers Transport Holland</td>\n",
       "      <td>Trucking company</td>\n",
       "      <td>51.597249</td>\n",
       "      <td>5.027990</td>\n",
       "      <td>Tilburg</td>\n",
       "      <td>4.6</td>\n",
       "      <td>53.0</td>\n",
       "      <td>*nk1l</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>a year ago</td>\n",
       "      <td>2022-09-24</td>\n",
       "      <td>5.0</td>\n",
       "      <td>better place with very good people everything ...</td>\n",
       "      <td>ENG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               name       type_company        lat       lon  \\\n",
       "0  Caretrex warehousing & logistics  Logistics service  51.593721  5.073492   \n",
       "1  Caretrex warehousing & logistics  Logistics service  51.593721  5.073492   \n",
       "2                    FEFA Logistics   Trucking company  51.480074  5.446764   \n",
       "3         Dekkers Transport Holland   Trucking company  51.597249  5.027990   \n",
       "4         Dekkers Transport Holland   Trucking company  51.597249  5.027990   \n",
       "\n",
       "        city  avg_stars_num  n_reviews_num encoded_user  local_guide  \\\n",
       "0    Tilburg            5.0            2.0        HHpDM          0.0   \n",
       "1    Tilburg            5.0            2.0        dYFWx          0.0   \n",
       "2  Eindhoven            NaN            NaN          NaN          NaN   \n",
       "3    Tilburg            4.6           53.0        Pp1)c          0.0   \n",
       "4    Tilburg            4.6           53.0        *nk1l          0.0   \n",
       "\n",
       "   clean_other_review_num published_date  today_date  stars_num  \\\n",
       "0                     4.0    2 years ago  2022-09-24        5.0   \n",
       "1                     1.0    5 years ago  2022-09-24        5.0   \n",
       "2                     NaN            NaN         NaN        NaN   \n",
       "3                     5.0     a year ago  2022-09-24        5.0   \n",
       "4                     2.0     a year ago  2022-09-24        5.0   \n",
       "\n",
       "                                           review_EN original_lang  \n",
       "0                                                NaN           NaN  \n",
       "1                                                NaN           NaN  \n",
       "2                                                NaN           NaN  \n",
       "3  Best employer ever. Worked there for approxima...           ENG  \n",
       "4  better place with very good people everything ...           ENG  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# main_dir = \n",
    "Dataset_name = 'TechLabsDataset.csv' \n",
    "DataDictionary_name = 'TechLabsDataset_Dictionary.csv'\n",
    "\n",
    "Dataset = pd.read_csv(os.path.join('./Data/',Dataset_name), index_col = 0)\n",
    "DataDictionary = pd.read_csv(os.path.join('./Data/',DataDictionary_name), index_col = 0)\n",
    "Dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0aeaec1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_EN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Best employer ever. Worked there for approxima...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>better place with very good people everything ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Nice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Good firm. The staff are very welcoming and f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Top company, and coffee, so recommended\\n\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           review_EN\n",
       "3  Best employer ever. Worked there for approxima...\n",
       "4  better place with very good people everything ...\n",
       "5                                               Nice\n",
       "6   Good firm. The staff are very welcoming and f...\n",
       "7        Top company, and coffee, so recommended\\n\\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df = pd.DataFrame(Dataset[~Dataset['review_EN'].isnull()]['review_EN'])\n",
    "review_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5d8e532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find emo\n",
    "def find_emo(text):\n",
    "    # find emoji and add to list\n",
    "    all_emoji = demoji.findall(text)\n",
    "    emo = ''\n",
    "    if len(all_emoji)>0:\n",
    "        for i,j in enumerate(all_emoji):\n",
    "            # list emo\n",
    "            emo = emo+','+all_emoji[j]\n",
    "    return emo\n",
    "\n",
    "\n",
    "# replace emo with empty text\n",
    "def replace_emo(text):\n",
    "    # find emo and replce with empty text\n",
    "    all_emoji = demoji.findall(text)\n",
    "\n",
    "    if len(all_emoji)>0:\n",
    "        for i,j in enumerate(all_emoji):\n",
    "            text = text.replace(j,'')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc1f4fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add emo\n",
    "review_df['emo'] = review_df['review_EN'].apply(lambda x: find_emo(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59411bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add review with no emo\n",
    "review_df['review_no_emo'] = review_df['review_EN'].apply(lambda x: replace_emo(x))\n",
    "# review_df[review_df['emo']!=''][['review_no_emo','emo']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17427550",
   "metadata": {},
   "source": [
    "# NLP pre-processing on review_df['review_no_emo']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "510f0781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get clean lemmas\n",
    "def get_clean_lemma(text):  \n",
    "    text = [token.lemma_ for token in nlp(text.lower()) if\n",
    "                  not token.is_punct\n",
    "                  and not token.is_currency\n",
    "                  and not token.is_digit\n",
    "                  and not token.is_punct\n",
    "    #               and not token.is_oov# is out of vocabulary\n",
    "                  and not token.is_space\n",
    "                  and not token.is_stop\n",
    "                  and not token.like_num\n",
    "                  and not token.pos_== 'PUNCT'\n",
    "                          ]\n",
    "    return text\n",
    "\n",
    "\n",
    "# # get tags per token\n",
    "# def get_tag_lemma(text): \n",
    "#     tag_list = [token.pos_ for token in nlp(text.lower()) if\n",
    "#                   not token.is_punct\n",
    "#                   and not token.is_currency\n",
    "#                   and not token.is_digit\n",
    "#                   and not token.is_punct\n",
    "#     #               and not token.is_oov# is out of vocabulary\n",
    "#                   and not token.is_space\n",
    "#                   and not token.is_stop\n",
    "#                   and not token.like_num\n",
    "#                           ]\n",
    "#     # ['NN','NNS','NNP','NNPS'] nouns\n",
    "#     # ['JJ','JJR','JJS'] adjectives\n",
    "#     # ['RB','RBR','RBS'] adverbs\n",
    "#     # ['VB','VBD','VBG','VBN','VBP','VBZ'] verbs\n",
    "#     return tag_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fab2921",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# check attribute of token in spacy: https://spacy.io/api/token\n",
    "\n",
    "# list of stop words in spacy\n",
    "# spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "# print('Number of stop words: %d' % len(spacy_stopwords))\n",
    "# print('First ten stop words: %s' % list(spacy_stopwords))\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "review_df['text_lemmas'] = review_df['review_no_emo'].apply(lambda x: get_clean_lemma(x))\n",
    "# review_df['lemmas_tags'] = review_df['review_no_emo'].apply(lambda x: get_tag_lemma(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4778309",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "concatenate_all_tokens = sum(review_df['text_lemmas'].tolist(),[])\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "word_counts = Counter(concatenate_all_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "735c36a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts_df = pd.DataFrame.from_dict(word_counts, orient='index').reset_index()\n",
    "word_counts_df.columns = ['word','#']\n",
    "word_counts_df.sort_values('#',ascending = False, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0438fcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts_df['tag'] = word_counts_df['word'].apply(lambda x: nlp(x)[0].pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5bc8936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ADJ', 'ADP', 'ADV', 'AUX', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM',\n",
       "       'PART', 'PRON', 'PROPN', 'PUNCT', 'SCONJ', 'SPACE', 'SYM', 'VERB',\n",
       "       'X'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(word_counts_df['tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "619d535b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>#</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>dutch</td>\n",
       "      <td>22</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1617</th>\n",
       "      <td>e</td>\n",
       "      <td>13</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>counter</td>\n",
       "      <td>12</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>&gt;</td>\n",
       "      <td>11</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>km</td>\n",
       "      <td>10</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>etc</td>\n",
       "      <td>9</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>k</td>\n",
       "      <td>8</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091</th>\n",
       "      <td>de</td>\n",
       "      <td>8</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>scammer</td>\n",
       "      <td>8</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1347</th>\n",
       "      <td>+</td>\n",
       "      <td>7</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>downstairs</td>\n",
       "      <td>6</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1933</th>\n",
       "      <td>t</td>\n",
       "      <td>6</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2572</th>\n",
       "      <td>kid</td>\n",
       "      <td>5</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2028</th>\n",
       "      <td>b</td>\n",
       "      <td>5</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>s</td>\n",
       "      <td>4</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>d</td>\n",
       "      <td>4</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3589</th>\n",
       "      <td>logic4u</td>\n",
       "      <td>3</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1802</th>\n",
       "      <td>adhere</td>\n",
       "      <td>2</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1883</th>\n",
       "      <td>24h</td>\n",
       "      <td>2</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2437</th>\n",
       "      <td>poke</td>\n",
       "      <td>2</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2667</th>\n",
       "      <td>â</td>\n",
       "      <td>2</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1326</th>\n",
       "      <td>zwolle</td>\n",
       "      <td>2</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1655</th>\n",
       "      <td>x</td>\n",
       "      <td>2</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3770</th>\n",
       "      <td>packs.nl</td>\n",
       "      <td>1</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3510</th>\n",
       "      <td>mtb</td>\n",
       "      <td>1</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2823</th>\n",
       "      <td>toilet.close</td>\n",
       "      <td>1</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2761</th>\n",
       "      <td>fahrer</td>\n",
       "      <td>1</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2759</th>\n",
       "      <td>ato</td>\n",
       "      <td>1</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2755</th>\n",
       "      <td>ham</td>\n",
       "      <td>1</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2768</th>\n",
       "      <td>pr</td>\n",
       "      <td>1</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3744</th>\n",
       "      <td>jk</td>\n",
       "      <td>1</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3456</th>\n",
       "      <td>doi</td>\n",
       "      <td>1</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3605</th>\n",
       "      <td>entitle</td>\n",
       "      <td>1</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3202</th>\n",
       "      <td>flexpoint.nl</td>\n",
       "      <td>1</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3619</th>\n",
       "      <td>iamandi</td>\n",
       "      <td>1</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3648</th>\n",
       "      <td>vd</td>\n",
       "      <td>1</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3584</th>\n",
       "      <td>partners.we</td>\n",
       "      <td>1</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3145</th>\n",
       "      <td>interfreight</td>\n",
       "      <td>1</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1204</th>\n",
       "      <td>2h30min</td>\n",
       "      <td>1</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1171</th>\n",
       "      <td>tho</td>\n",
       "      <td>1</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1158</th>\n",
       "      <td>ot-09</td>\n",
       "      <td>1</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154</th>\n",
       "      <td>afsluitdijk</td>\n",
       "      <td>1</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1812</th>\n",
       "      <td>delivery.very</td>\n",
       "      <td>1</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>bol.com</td>\n",
       "      <td>1</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>​​of</td>\n",
       "      <td>1</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2500</th>\n",
       "      <td>mo</td>\n",
       "      <td>1</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2417</th>\n",
       "      <td>g</td>\n",
       "      <td>1</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2587</th>\n",
       "      <td>100x</td>\n",
       "      <td>1</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2614</th>\n",
       "      <td>v</td>\n",
       "      <td>1</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1857</th>\n",
       "      <td>f</td>\n",
       "      <td>1</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2110</th>\n",
       "      <td>receipt.now</td>\n",
       "      <td>1</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2278</th>\n",
       "      <td>nb</td>\n",
       "      <td>1</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2113</th>\n",
       "      <td>service.of</td>\n",
       "      <td>1</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2210</th>\n",
       "      <td>him/</td>\n",
       "      <td>1</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               word   # tag\n",
       "551           dutch  22   X\n",
       "1617              e  13   X\n",
       "707         counter  12   X\n",
       "325               >  11   X\n",
       "406              km  10   X\n",
       "233             etc   9   X\n",
       "1979              k   8   X\n",
       "1091             de   8   X\n",
       "1444        scammer   8   X\n",
       "1347              +   7   X\n",
       "461      downstairs   6   X\n",
       "1933              t   6   X\n",
       "2572            kid   5   X\n",
       "2028              b   5   X\n",
       "162               s   4   X\n",
       "947               d   4   X\n",
       "3589        logic4u   3   X\n",
       "1802         adhere   2   X\n",
       "1883            24h   2   X\n",
       "2437           poke   2   X\n",
       "2667              â   2   X\n",
       "1326         zwolle   2   X\n",
       "1655              x   2   X\n",
       "3770       packs.nl   1   X\n",
       "3510            mtb   1   X\n",
       "2823   toilet.close   1   X\n",
       "2761         fahrer   1   X\n",
       "2759            ato   1   X\n",
       "2755            ham   1   X\n",
       "2768             pr   1   X\n",
       "3744             jk   1   X\n",
       "3456            doi   1   X\n",
       "3605        entitle   1   X\n",
       "3202   flexpoint.nl   1   X\n",
       "3619        iamandi   1   X\n",
       "3648             vd   1   X\n",
       "3584    partners.we   1   X\n",
       "3145   interfreight   1   X\n",
       "1204        2h30min   1   X\n",
       "1171            tho   1   X\n",
       "1158          ot-09   1   X\n",
       "1154    afsluitdijk   1   X\n",
       "1812  delivery.very   1   X\n",
       "281         bol.com   1   X\n",
       "1029           ​​of   1   X\n",
       "2500             mo   1   X\n",
       "2417              g   1   X\n",
       "2587           100x   1   X\n",
       "2614              v   1   X\n",
       "1857              f   1   X\n",
       "2110    receipt.now   1   X\n",
       "2278             nb   1   X\n",
       "2113     service.of   1   X\n",
       "2210           him/   1   X"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "word_counts_df[word_counts_df['tag']=='X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "504837b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tag_short' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m word_counts_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtag_short\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mword_counts_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtag\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtag_short\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/environment/lib/python3.9/site-packages/pandas/core/series.py:4433\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4323\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4324\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4325\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4328\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4329\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4330\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4331\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4332\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4431\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4432\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/environment/lib/python3.9/site-packages/pandas/core/apply.py:1082\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;66;03m# if we are a string, try to dispatch\u001b[39;00m\n\u001b[1;32m   1080\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[0;32m-> 1082\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/environment/lib/python3.9/site-packages/pandas/core/apply.py:1137\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m   1132\u001b[0m         \u001b[38;5;66;03m# error: Argument 2 to \"map_infer\" has incompatible type\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m         \u001b[38;5;66;03m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001b[39;00m\n\u001b[1;32m   1134\u001b[0m         \u001b[38;5;66;03m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m         \u001b[38;5;66;03m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;66;03m# \"Callable[[Any], Any]\"\u001b[39;00m\n\u001b[0;32m-> 1137\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1138\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1139\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1140\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1141\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1144\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1145\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/environment/lib/python3.9/site-packages/pandas/_libs/lib.pyx:2870\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m word_counts_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtag_short\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m word_counts_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtag\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mtag_short\u001b[49m(x))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tag_short' is not defined"
     ]
    }
   ],
   "source": [
    "word_counts_df['tag_short'] = word_counts_df['tag'].apply(lambda x: tag_short(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce752562",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts_df[word_counts_df['tag_short']=='adverbs']['word'].tolist()\n",
    "['ea','p.m.','not','a.m.','ear','har','eurostar','tattoo','semi','ex-','right.only',\n",
    " 'there.fast','gtv','bezeike','alphen','off.a','cbk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbced4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts_df[word_counts_df['tag_short']=='verbs']['word'].tolist()\n",
    "# ['ea','p.m.','not','a.m.','ear','har','eurostar','tattoo','semi','ex-','right.only',\n",
    "#  'there.fast','gtv','bezeike','alphen','off.a','cbk']\n",
    "['netherlands','cmr','ref','den','fl','tci','lug','b.v','kamado','luxembourg','cm','bo','bah','bio','m','nico',\n",
    "'logistics&move','ist','lorentaweg','sweden','co','amir',\n",
    " 'rabote','fajn','om','cove',\n",
    " 'leadl''patrick',\n",
    " 'toplogistiek','toitoi','swerve','lkw','aceo',\n",
    " 'melden','ce',\n",
    " 'satay',\n",
    " 'manfre',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56448f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts_df[word_counts_df['tag_short']=='nouns']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
